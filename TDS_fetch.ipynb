{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNJvXuKyIYefpC7EHj0mtKe"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7mZIAvVe7FGH","executionInfo":{"status":"ok","timestamp":1730115615518,"user_tz":-330,"elapsed":7948,"user":{"displayName":"Baishali Das","userId":"14561243175500141205"}},"outputId":"9053b9a1-0de7-4b25-aa42-ee0e5f0b1783"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n"]}],"source":["!pip install requests\n"]},{"cell_type":"code","source":["import requests\n","import time\n","import csv\n"],"metadata":{"id":"ThradTIr7VRe","executionInfo":{"status":"ok","timestamp":1730125906467,"user_tz":-330,"elapsed":425,"user":{"displayName":"Baishali Das","userId":"14561243175500141205"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["\n","# GitHub API settings\n","GITHUB_TOKEN = \"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\"\n","BASE_URL = \"https://api.github.com\"\n","HEADERS = {\n","    \"Authorization\": f\"token {GITHUB_TOKEN}\",\n","    \"Accept\": \"application/vnd.github.v3+json\"\n","}\n","\n","# Function to get cleaned-up company names\n","def clean_company_name(company):\n","    if company:\n","        return company.strip().lstrip(\"@\").upper()\n","    return \"\"\n","\n","# Fetch detailed user information\n","def fetch_user_details(username):\n","    url = f\"{BASE_URL}/users/{username}\"\n","    response = requests.get(url, headers=HEADERS)\n","    if response.status_code == 200:\n","        user_data = response.json()\n","        return {\n","            \"login\": user_data.get(\"login\", \"\"),\n","            \"name\": user_data.get(\"name\", \"\"),\n","            \"company\": clean_company_name(user_data.get(\"company\", \"\")),\n","            \"location\": user_data.get(\"location\", \"\"),\n","            \"email\": user_data.get(\"email\", \"\"),\n","            \"hireable\": user_data.get(\"hireable\", \"\"),\n","            \"bio\": user_data.get(\"bio\", \"\"),\n","            \"public_repos\": user_data.get(\"public_repos\", 0),\n","            \"followers\": user_data.get(\"followers\", 0),\n","            \"following\": user_data.get(\"following\", 0),\n","            \"created_at\": user_data.get(\"created_at\", \"\")\n","        }\n","    else:\n","        print(f\"Failed to fetch details for user {username}\")\n","        return None\n","\n","# Fetch repository data for a user\n","def fetch_user_repos(username, max_repos=500):\n","    repos = []\n","    page = 1\n","    while len(repos) < max_repos:\n","        url = f\"{BASE_URL}/users/{username}/repos?page={page}&per_page=100\"\n","        response = requests.get(url, headers=HEADERS)\n","        if response.status_code != 200:\n","            print(f\"Failed to fetch repositories for {username}\")\n","            break\n","\n","        repo_data = response.json()\n","        if not repo_data:\n","            break\n","\n","        for repo in repo_data:\n","            if len(repos) >= max_repos:\n","                break\n","            repos.append({\n","                \"login\": username,\n","                \"full_name\": repo.get(\"full_name\", \"\"),\n","                \"created_at\": repo.get(\"created_at\", \"\"),\n","                \"stargazers_count\": repo.get(\"stargazers_count\", 0),\n","                \"watchers_count\": repo.get(\"watchers_count\", 0),\n","                \"language\": repo.get(\"language\", \"\"),\n","                \"has_projects\": repo.get(\"has_projects\", False),\n","                \"has_wiki\": repo.get(\"has_wiki\", False),\n","                \"license_name\": repo[\"license\"][\"name\"] if repo.get(\"license\") else \"\"\n","            })\n","\n","        page += 1\n","        time.sleep(1)\n","\n","    return repos\n","\n","# Fetch users in Hyderabad with >50 followers\n","def fetch_hyderabad_users(min_followers=50):\n","    users = []\n","    page = 1\n","    while True:\n","        query = f\"location:Hyderabad followers:>{min_followers}\"\n","        url = f\"{BASE_URL}/search/users?q={query}&page={page}&per_page=100\"\n","        response = requests.get(url, headers=HEADERS)\n","        if response.status_code != 200:\n","            print(f\"Error fetching users: {response.status_code}\")\n","            break\n","\n","        data = response.json()\n","        users.extend(data[\"items\"])\n","        if \"next\" not in response.links:\n","            break\n","\n","        page += 1\n","        time.sleep(1)\n","\n","    return users\n","\n","# Fetch detailed data for all users and their repositories\n","def fetch_all_data(min_followers=50):\n","    users = fetch_hyderabad_users(min_followers)\n","    user_data = []\n","    repo_data = []\n","\n","    for user in users:\n","        username = user[\"login\"]\n","        user_details = fetch_user_details(username)\n","        if user_details:\n","            user_data.append(user_details)\n","            repos = fetch_user_repos(username)\n","            repo_data.extend(repos)\n","\n","    return user_data, repo_data\n","\n","# Save data to CSV\n","def save_to_csv(user_data, repo_data):\n","    # Save users.csv\n","    with open(\"users.csv\", \"w\", newline=\"\") as file:\n","        fieldnames = [\"login\", \"name\", \"company\", \"location\", \"email\", \"hireable\", \"bio\", \"public_repos\", \"followers\", \"following\", \"created_at\"]\n","        writer = csv.DictWriter(file, fieldnames=fieldnames)\n","        writer.writeheader()\n","        writer.writerows(user_data)\n","\n","    # Save repositories.csv\n","    with open(\"repositories.csv\", \"w\", newline=\"\") as file:\n","        fieldnames = [\"login\", \"full_name\", \"created_at\", \"stargazers_count\", \"watchers_count\", \"language\", \"has_projects\", \"has_wiki\", \"license_name\"]\n","        writer = csv.DictWriter(file, fieldnames=fieldnames)\n","        writer.writeheader()\n","        writer.writerows(repo_data)\n","\n","# Fetch all data and save to CSV\n","user_data, repo_data = fetch_all_data(min_followers=50)\n","save_to_csv(user_data, repo_data)\n"],"metadata":{"id":"iW7Q_3nKikZ_","executionInfo":{"status":"ok","timestamp":1730127404954,"user_tz":-330,"elapsed":1417129,"user":{"displayName":"Baishali Das","userId":"14561243175500141205"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"jdWGL126ikdG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"7LxQh71Vikf-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Sdq2pkyBiki6"},"execution_count":null,"outputs":[]}]}